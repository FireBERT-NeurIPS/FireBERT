{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial sample generation with code from the TextFooler paper\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "1. TextFooler required resources: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_fitting_embeddings_path = 'resources/embeddings/counter-fitted-vectors.txt'\n",
    "counter_fitting_cos_sim_path = 'resources/cos_sim_counter_fitting.npy'\n",
    "USE_cache_path = 'scratch/tf_cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Path of the tuned model to fool and it's training task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'imdb' # can be imdb or mnli\n",
    "#model_path = 'resources/models/IMDB/pytorch_model.bin'\n",
    "#model_path = 'resources/models/IMDB_on_lightning/pytorch_model.bin'\n",
    "model_path = 'resources/models/co-tuned_IMDB_on_lightning_final_filter/pytorch_model.bin'\n",
    "\n",
    "#task = 'mnli' # can be imdb or mnli\n",
    "#model_path = 'resources/models/MNLI/pytorch_model.bin'\n",
    "#model_path = 'resources/models/MNLI_on_lightning/pytorch_model.bin'\n",
    "#model_path = 'resources/models/co-tuned_MNLI_on_lightning_final_filter/pytorch_model.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Path of the dataset to generate samples from and the name of the output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB:\n",
    "\n",
    "#dataset_path = 'data/IMDB/imdb_train.txt'\n",
    "#output_path = 'data/IMDB/generated/imdb_adversarial_samples_for_train'\n",
    "#dataset_path = 'data/IMDB/imdb_dev.txt'\n",
    "#output_path = 'data/IMDB/generated/imdb_adversarial_samples_for_dev'\n",
    "#dataset_path = 'data/IMDB/imdb_test.txt'\n",
    "#output_path = 'data/IMDB/generated/imdb_adversarial_samples_for_test'\n",
    "\n",
    "# MNLI:\n",
    "\n",
    "#dataset_path = 'data/MNLI/original/multinli_1.0_train.txt'\n",
    "#output_path = 'data/MNLI/generated/mnli_adversarial_samples_for_train'\n",
    "#dataset_path = 'data/MNLI/original/multinli_1.0_dev_matched.txt'\n",
    "#output_path = 'data/MNLI/generated/mnli_adversarial_samples_for_dev'\n",
    "#dataset_path = 'data/MNLI/original/multinli_1.0_dev_mismatched.txt'\n",
    "#output_path = 'data/MNLI/generated/mnli_adversarial_samples_for_test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The number of samples to process from the dataset and batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset size is 40000 for imdb train and 390702 for MNLI train\n",
    "# dev and test dataset sizes are 5K for IMDB and 10K for MNLI\n",
    "#data_size = 390703 #add one for the header row that is skipped in the logic\n",
    "#batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want to run against the TextFooler sample data (for example, to compare baselines), use these dataset paths instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with just the textfooler sample data\n",
    "dataset_path = 'data/TextFooler/imdb'\n",
    "#dataset_path = 'data/TextFooler/mnli_matched'\n",
    "data_size = 1000\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run TextFooler against one of our evaluation purtubation models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kevin/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, Dataset, SequentialSampler, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from processors import MnliProcessor, ImdbProcessor\n",
    "from bert_base_model import LightningBertForSequenceClassification\n",
    "from firebert_fse import FireBERT_FSE\n",
    "from firebert_fve import FireBERT_FVE\n",
    "\n",
    "import string\n",
    "import switch\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "from transformers.data.processors.utils import DataProcessor, InputExample, InputFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text fooler logic that we generalized and encapsulated in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The TextFooler algorithm in a class for generating adversarial texts. Adapted to work with a BERT\n",
    "classifier tuned as a PyTorch Lightning model.\n",
    "\n",
    "This class was adapted from code by TextFooler at https://github.com/jind11/TextFooler,\n",
    "a code repository in support of the paper:\n",
    "\n",
    "Jin, Di, et al. \"Is BERT Really Robust? Natural Language Attack on Text Classification and Entailment.\"\n",
    "arXiv preprint arXiv:1907.11932 (2019).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class PaperFooler(object):\n",
    "    def __init__(self,\n",
    "                 tokenizer,\n",
    "                 lightning_model,\n",
    "                 USE_cache_path,\n",
    "                 counter_fitting_embeddings_path,\n",
    "                 counter_fitting_cos_sim_path=None,\n",
    "                 max_seq_length=128):\n",
    "        super(PaperFooler, self).__init__()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = lightning_model.cuda()\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "        # prepare synonym extractor\n",
    "        # build dictionary via the embedding file\n",
    "        print(\"Building vocab...\")\n",
    "        self.idx2word = {}\n",
    "        self.word2idx = {}\n",
    "\n",
    "        with open(counter_fitting_embeddings_path, 'r', encoding=\"utf-8\") as ifile:\n",
    "            for line in ifile:\n",
    "                word = line.split()[0]\n",
    "                if word not in self.idx2word:\n",
    "                    self.idx2word[len(self.idx2word)] = word\n",
    "                    self.word2idx[word] = len(self.idx2word) - 1\n",
    "\n",
    "        # for cosine similarity matrix\n",
    "        print(\"Building cos sim matrix...\")\n",
    "        if counter_fitting_cos_sim_path:\n",
    "            # load pre-computed cosine similarity matrix if provided\n",
    "            print('Load pre-computed cosine similarity matrix from {}'.format(counter_fitting_cos_sim_path))\n",
    "            self.cos_sim = np.load(counter_fitting_cos_sim_path)\n",
    "        else:\n",
    "            # calculate the cosine similarity matrix\n",
    "            print('Start computing the cosine similarity matrix!')\n",
    "            embeddings = []\n",
    "            with open(counter_fitting_embeddings_path, 'r') as ifile:\n",
    "                for line in ifile:\n",
    "                    embedding = [float(num) for num in line.strip().split()[1:]]\n",
    "                    embeddings.append(embedding)\n",
    "            embeddings = np.array(embeddings)\n",
    "            product = np.dot(embeddings, embeddings.T)\n",
    "            norm = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "            self.cos_sim = product / np.dot(norm, norm.T)\n",
    "        print(\"Cos sim import finished!\")\n",
    "\n",
    "        # build the semantic similarity module\n",
    "        self.sim_predictor = USE(USE_cache_path)\n",
    "\n",
    "        self.stop_words_set = switch.get_stopwords()\n",
    "  \n",
    "\n",
    "    def text_pred(self, text_data, batch_size):\n",
    "        # Switch the model to eval mode.\n",
    "        self.model.eval()\n",
    "\n",
    "        # transform text data into a batch of indices\n",
    "        batch = self.transform_text(text_data, batch_size)\n",
    "\n",
    "        probs_all = []\n",
    "        for input_ids, attention_mask, token_type_ids, ex_idx in batch:\n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "            token_type_ids = token_type_ids.cuda()\n",
    "            ex_idx = ex_idx.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                    token_type_ids=token_type_ids, example_idx=ex_idx)\n",
    "                probs = nn.functional.softmax(logits, dim=-1)\n",
    "                probs_all.append(probs)\n",
    "\n",
    "        return torch.cat(probs_all, dim=0)\n",
    "\n",
    "\n",
    "    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "\n",
    "    def convert_examples_to_features(self, examples, max_seq_length, tokenizer):\n",
    "        \"\"\"Loads a data file into a list of `InputFeature`s.\"\"\"\n",
    "\n",
    "        features = []\n",
    "        for (ex_index, (text_a, text_b)) in enumerate(examples):\n",
    "            tokens_a = tokenizer.tokenize(' '.join(text_a))\n",
    "\n",
    "            tokens_b = None\n",
    "            if text_b:\n",
    "                tokens_b = tokenizer.tokenize(' '.join(text_b))\n",
    "                # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "                # length is less than the specified length.\n",
    "                # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "                self._truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "            else:\n",
    "                # Account for [CLS] and [SEP] with \"- 2\"\n",
    "                if len(tokens_a) > max_seq_length - 2:\n",
    "                    tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "            token_type_ids = [0] * len(tokens)\n",
    "\n",
    "            if tokens_b:\n",
    "                tokens += tokens_b + [\"[SEP]\"]\n",
    "                token_type_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "            # tokens are attended to.\n",
    "            attention_mask = [1] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding = [0] * (max_seq_length - len(input_ids))\n",
    "            input_ids += padding\n",
    "            attention_mask += padding\n",
    "            token_type_ids += padding\n",
    "\n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(attention_mask) == max_seq_length\n",
    "            assert len(token_type_ids) == max_seq_length\n",
    "\n",
    "            features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              attention_mask=attention_mask,\n",
    "                              token_type_ids=token_type_ids))\n",
    "        return features\n",
    "\n",
    "    def transform_text(self, data, batch_size):\n",
    "        # transform data into seq of embeddings\n",
    "        eval_features = self.convert_examples_to_features(list(zip(data['text_a'], data['text_b'])),\n",
    "                                                          self.max_seq_length, self.tokenizer)\n",
    "\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([f.attention_mask for f in eval_features], dtype=torch.long)\n",
    "        all_token_type_ids = torch.tensor([f.token_type_ids for f in eval_features], dtype=torch.long)\n",
    "        all_idxs = torch.tensor([i for i in range(len(all_input_ids))], dtype=torch.long)\n",
    "        \n",
    "        eval_data = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_idxs)\n",
    "\n",
    "        # Run prediction for data sequentially\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=batch_size)\n",
    "\n",
    "        return eval_dataloader\n",
    "    \n",
    "    def pick_most_similar_words_batch(self, src_words, sim_mat, idx2word, ret_count=10, threshold=0.):\n",
    "        \"\"\"\n",
    "        embeddings is a matrix with (d, vocab_size)\n",
    "        \"\"\"\n",
    "        sim_order = np.argsort(-sim_mat[src_words, :])[:, 1:1 + ret_count]\n",
    "        sim_words, sim_values = [], []\n",
    "        for idx, src_word in enumerate(src_words):\n",
    "            sim_value = sim_mat[src_word][sim_order[idx]]\n",
    "            mask = sim_value >= threshold\n",
    "            sim_word, sim_value = sim_order[idx][mask], sim_value[mask]\n",
    "            sim_word = [idx2word[id] for id in sim_word]\n",
    "            sim_words.append(sim_word)\n",
    "            sim_values.append(sim_value)\n",
    "        return sim_words, sim_values\n",
    "\n",
    "    def pos_filter(self, ori_pos, new_pos_list):\n",
    "        same = [True if ori_pos == new_pos or (set([ori_pos, new_pos]) <= set(['NOUN', 'VERB']))\n",
    "                else False\n",
    "                for new_pos in new_pos_list]\n",
    "        return same    \n",
    "         \n",
    "    def generate_adversarial(self, task, text_a, text_b, true_label, batch_size,\n",
    "           import_score_threshold=-1., sim_score_threshold=0.7, sim_score_window=15, synonym_num=50):\n",
    "        # first check the prediction of the original text\n",
    "        orig_probs = self.text_pred({'text_a': [text_a], 'text_b': [text_b]}, batch_size).squeeze()\n",
    "        orig_label = torch.argmax(orig_probs)\n",
    "        orig_prob = orig_probs.max()\n",
    "        text_ls = text_b if task == 'mnli' else text_a\n",
    "        if true_label != orig_label:\n",
    "            return '', 0, orig_label, orig_label, 0\n",
    "        else:\n",
    "            len_text = len(text_ls)\n",
    "            if len_text < sim_score_window:\n",
    "                sim_score_threshold = 0.1  # shut down the similarity thresholding function\n",
    "            half_sim_score_window = (sim_score_window - 1) // 2\n",
    "            num_queries = 1\n",
    "\n",
    "            # get the pos and verb tense info\n",
    "            pos_ls = switch.get_pos(text_ls)\n",
    "\n",
    "            # get importance score\n",
    "            leave_1_texts = [text_ls[:ii]+['<oov>']+text_ls[min(ii+1, len_text):] for ii in range(len_text)]\n",
    "            if task == 'mnli':\n",
    "                leave_1_probs = self.text_pred({'text_a':[text_a]*len_text, 'text_b': leave_1_texts}, batch_size)\n",
    "            else:\n",
    "                leave_1_probs = self.text_pred({'text_a':leave_1_texts, 'text_b': [text_b]*len_text}, batch_size)                      \n",
    "            num_queries += len(leave_1_texts)\n",
    "            leave_1_probs_argmax = torch.argmax(leave_1_probs, dim=-1)\n",
    "            import_scores = (orig_prob - leave_1_probs[:, orig_label] + (leave_1_probs_argmax != orig_label).float() * (\n",
    "                        leave_1_probs.max(dim=-1)[0] - torch.index_select(orig_probs, 0,\n",
    "                                                                          leave_1_probs_argmax))).data.cpu().numpy()\n",
    "\n",
    "            # get words to perturb ranked by importance score for word in words_perturb\n",
    "            words_perturb = []\n",
    "            for idx, score in sorted(enumerate(import_scores), key=lambda x: x[1], reverse=True):\n",
    "                if score > import_score_threshold and text_ls[idx] not in self.stop_words_set:\n",
    "                    words_perturb.append((idx, text_ls[idx]))\n",
    "\n",
    "            # find synonyms\n",
    "            words_perturb_idx = [self.word2idx[word] for idx, word in words_perturb if word in self.word2idx]\n",
    "            #src_words, sim_mat, idx2word, ret_count=10, threshold=0.\n",
    "            synonym_words, _ = self.pick_most_similar_words_batch(words_perturb_idx, self.cos_sim, \n",
    "                                                                  self.idx2word, synonym_num, 0.5)\n",
    "            synonyms_all = []\n",
    "            for idx, word in words_perturb:\n",
    "                if word in self.word2idx:\n",
    "                    synonyms = synonym_words.pop(0)\n",
    "                    if synonyms:\n",
    "                        synonyms_all.append((idx, synonyms))\n",
    "\n",
    "            # start replacing and attacking\n",
    "            text_prime = text_ls[:]\n",
    "            text_cache = text_prime[:]\n",
    "            num_changed = 0\n",
    "            for idx, synonyms in synonyms_all:\n",
    "                new_texts = [text_prime[:idx] + [synonym] + text_prime[min(idx + 1, len_text):] for synonym in synonyms]\n",
    "                if task == 'mnli':\n",
    "                    new_probs = self.text_pred({'text_a': [text_a] * len(synonyms), 'text_b': new_texts}, batch_size)\n",
    "                else:\n",
    "                    new_probs = self.text_pred({'text_a': new_texts, 'text_b': [text_b] * len(synonyms)}, batch_size)\n",
    "                \n",
    "                # compute semantic similarity\n",
    "                if idx >= half_sim_score_window and len_text - idx - 1 >= half_sim_score_window:\n",
    "                    text_range_min = idx - half_sim_score_window\n",
    "                    text_range_max = idx + half_sim_score_window + 1\n",
    "                elif idx < half_sim_score_window and len_text - idx - 1 >= half_sim_score_window:\n",
    "                    text_range_min = 0\n",
    "                    text_range_max = sim_score_window\n",
    "                elif idx >= half_sim_score_window and len_text - idx - 1 < half_sim_score_window:\n",
    "                    text_range_min = len_text - sim_score_window\n",
    "                    text_range_max = len_text\n",
    "                else:\n",
    "                    text_range_min = 0\n",
    "                    text_range_max = len_text\n",
    "                semantic_sims = \\\n",
    "                    self.sim_predictor.semantic_sim([' '.join(text_cache[text_range_min:text_range_max])] * len(new_texts),\n",
    "                                           list(map(lambda x: ' '.join(x[text_range_min:text_range_max]), new_texts)))[0]\n",
    "                \n",
    "                num_queries += len(new_texts)\n",
    "                if len(new_probs.shape) < 2:\n",
    "                    new_probs = new_probs.unsqueeze(0)\n",
    "                new_probs_mask = (orig_label != torch.argmax(new_probs, dim=-1)).data.cpu().numpy()\n",
    "                # prevent bad synonyms\n",
    "                new_probs_mask *= (semantic_sims >= sim_score_threshold)\n",
    "                # prevent incompatible pos\n",
    "                synonyms_pos_ls = [switch.get_pos(new_text[max(idx - 4, 0):idx + 5])[min(4, idx)]\n",
    "                                   if len(new_text) > 10 else switch.get_pos(new_text)[idx] for new_text in new_texts]\n",
    "                pos_mask = np.array(self.pos_filter(pos_ls[idx], synonyms_pos_ls))\n",
    "                new_probs_mask *= pos_mask\n",
    "\n",
    "                if np.sum(new_probs_mask) > 0:\n",
    "                    text_prime[idx] = synonyms[(new_probs_mask * semantic_sims).argmax()]\n",
    "                    num_changed += 1\n",
    "                    break\n",
    "                else:\n",
    "                    new_label_probs = new_probs[:, orig_label] + torch.from_numpy(\n",
    "                        (semantic_sims < sim_score_threshold) + (1 - pos_mask).astype(float)).float().cuda()\n",
    "                    new_label_prob_min, new_label_prob_argmin = torch.min(new_label_probs, dim=-1)\n",
    "                    if new_label_prob_min < orig_prob:\n",
    "                        text_prime[idx] = synonyms[new_label_prob_argmin]\n",
    "                        num_changed += 1\n",
    "                text_cache = text_prime[:]\n",
    "            \n",
    "            if task == 'mnli':\n",
    "                new_label = torch.argmax(self.text_pred({'text_a':[text_a], 'text_b': [text_prime]}, batch_size))\n",
    "            else:\n",
    "                new_label = torch.argmax(self.text_pred({'text_a':[text_prime], 'text_b': [text_b]}, batch_size))\n",
    "\n",
    "            if true_label != new_label:\n",
    "                return TreebankWordDetokenizer().detokenize(text_prime), num_changed, orig_label, new_label, num_queries\n",
    "            else:\n",
    "                return '', num_changed, orig_label, new_label, num_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal Sentence Encoder encapsulated in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USE (Universal Sentence Encoder) in a class for determining semantic similarities.\n",
    "\n",
    "This class was adapted from code by TextFooler at https://github.com/jind11/TextFooler,\n",
    "a code repository in support of the paper:\n",
    "\n",
    "Jin, Di, et al. \"Is BERT Really Robust? Natural Language Attack on Text Classification and Entailment.\"\n",
    "arXiv preprint arXiv:1907.11932 (2019).\n",
    "\"\"\"\n",
    "\n",
    "class USE(object):\n",
    "    def __init__(self, cache_path):\n",
    "        super(USE, self).__init__()\n",
    "        #config =  tf.compat.v1.ConfigProto()\n",
    "        #config.gpu_options.allow_growth = True\n",
    "        #session =  tf.compat.v1.Session(config=config)\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=config)\n",
    "        #tf.compat.v1.disable_eager_execution()\n",
    "        \n",
    "        os.environ['TFHUB_CACHE_DIR'] = cache_path\n",
    "        module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "        self.embed = hub.Module(module_url)\n",
    "\n",
    "        self.build_graph()\n",
    "        self.sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "\n",
    "    def build_graph(self):\n",
    "        self.sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "        self.sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "        sts_encode1 = tf.nn.l2_normalize(self.embed(self.sts_input1), axis=1)\n",
    "        sts_encode2 = tf.nn.l2_normalize(self.embed(self.sts_input2), axis=1)\n",
    "        self.cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "        clip_cosine_similarities = tf.clip_by_value(self.cosine_similarities, -1.0, 1.0)\n",
    "        self.sim_scores = 1.0 - tf.acos(clip_cosine_similarities)\n",
    "\n",
    "    def semantic_sim(self, sents1, sents2):\n",
    "        scores = self.sess.run(\n",
    "            [self.sim_scores],\n",
    "            feed_dict={\n",
    "                self.sts_input1: sents1,\n",
    "                self.sts_input2: sents2,\n",
    "            })\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routines to read and scrub datasets (mnli and imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utilities for working with local datasets for processing.\n",
    "\n",
    "These methods were adapted from code by TextFooler at https://github.com/jind11/TextFooler,\n",
    "a code repository in support of the paper:\n",
    "\n",
    "Jin, Di, et al. \"Is BERT Really Robust? Natural Language Attack on Text Classification and Entailment.\"\n",
    "arXiv preprint arXiv:1907.11932 (2019).\n",
    "\"\"\"\n",
    "\n",
    "def clean_str(string, TREC=False):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip() if TREC else string.strip().lower()\n",
    "\n",
    "def read_corpus(path, data_size, clean=True, MR=True, encoding='utf8', shuffle=False, lower=True):\n",
    "    data = []\n",
    "    labels = []\n",
    "    empty = []\n",
    "    with open(path, encoding=encoding) as fin:\n",
    "        for idx, line in enumerate(fin):\n",
    "            if idx >= data_size:\n",
    "                break\n",
    "            if MR:\n",
    "                label, sep, text = line.partition(' ')\n",
    "                label = int(label)\n",
    "            else:\n",
    "                label, sep, text = line.partition(',')\n",
    "                label = int(label) - 1\n",
    "            if clean:\n",
    "                text = clean_str(text.strip()) if clean else text.strip()\n",
    "            if lower:\n",
    "                text = text.lower()\n",
    "            labels.append(label)\n",
    "            data.append(text.split())\n",
    "            empty.append(None)\n",
    "\n",
    "    if shuffle:\n",
    "        perm = list(range(len(data)))\n",
    "        random.shuffle(perm)\n",
    "        data = [data[i] for i in perm]\n",
    "        labels = [labels[i] for i in perm]\n",
    "\n",
    "    return {\"text_a\": data,\n",
    "            \"text_b\": empty,\n",
    "            \"label\": labels}\n",
    "\n",
    "def read_data(filepath, data_size, lowercase=False, ignore_punctuation=False, stopwords=[]):\n",
    "    \"\"\"\n",
    "    Read the premises, hypotheses and labels from some NLI dataset's\n",
    "    file and return them in a dictionary. The file should be in the same\n",
    "    form as SNLI's .txt files.\n",
    "\n",
    "    Args:\n",
    "        filepath: The path to a file containing some premises, hypotheses\n",
    "            and labels that must be read. The file should be formatted in\n",
    "            the same way as the SNLI (and MultiNLI) dataset.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing three lists, one for the premises, one for\n",
    "        the hypotheses, and one for the labels in the input data.\n",
    "    \"\"\"\n",
    "    \n",
    "    labeldict = {\"contradiction\": 0,\n",
    "                  \"entailment\": 1,\n",
    "                  \"neutral\": 2}\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf8') as input_data:\n",
    "        premises, hypotheses, labels = [], [], []\n",
    "\n",
    "        # Translation tables to remove punctuation from strings.\n",
    "        punct_table = str.maketrans({key: ' '\n",
    "                                     for key in string.punctuation})\n",
    "\n",
    "        for idx, line in enumerate(input_data):\n",
    "            if idx >= data_size:\n",
    "                break\n",
    "\n",
    "            line = line.strip().split('\\t')\n",
    "\n",
    "            # Ignore sentences that have no gold label.\n",
    "            if line[0] == '-':\n",
    "                continue\n",
    "            \n",
    "            # skip the header row (if there is one)\n",
    "            if line[0] == 'gold_label':\n",
    "                continue\n",
    "\n",
    "            premise = line[1]\n",
    "            hypothesis = line[2]\n",
    "\n",
    "            if lowercase:\n",
    "                premise = premise.lower()\n",
    "                hypothesis = hypothesis.lower()\n",
    "\n",
    "            if ignore_punctuation:\n",
    "                premise = premise.translate(punct_table)\n",
    "                hypothesis = hypothesis.translate(punct_table)\n",
    "                \n",
    "            # strip ('s and )'s\n",
    "            premise = premise.translate({ord(i):None for i in '()'})\n",
    "            hypothesis = hypothesis.translate({ord(i):None for i in '()'})\n",
    "            \n",
    "            # Each premise and hypothesis is split into a list of words.\n",
    "            premises.append([w for w in premise.rstrip().split()\n",
    "                             if w not in stopwords])\n",
    "            hypotheses.append([w for w in hypothesis.rstrip().split()\n",
    "                             if w not in stopwords])\n",
    "            labels.append(labeldict[line[0]])\n",
    "\n",
    "        return {\"text_a\": premises,\n",
    "                \"text_b\": hypotheses,\n",
    "                \"label\": labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routine to generate samples from the fooler and dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def elapsed_time():\n",
    "    global t_start\n",
    "\n",
    "    t_now = time.time()\n",
    "    t = t_now-t_start\n",
    "    t_start = t_now\n",
    "    return t\n",
    "\n",
    "def generate_samples(task, fooler, dataset_path, data_size, batch_size):\n",
    "    \n",
    "    # get data to attack, fetch first [data_size] data samples for adversarial attacking\n",
    "    \n",
    "    if task == 'mnli':\n",
    "        dataloader = read_data\n",
    "        labeldict = {0: \"contradiction\",\n",
    "                     1: \"entailment\",\n",
    "                     2:  \"neutral\"}\n",
    "    else:\n",
    "        #imdb\n",
    "        dataloader = read_corpus\n",
    "        labeldict = {0: 0, 1: 1}\n",
    "\n",
    "    data = dataloader(dataset_path, data_size)\n",
    "    print(\"Data import finished!\")\n",
    "        \n",
    "    test_examples = [InputExample(i, TreebankWordDetokenizer().detokenize(a), \n",
    "                                  TreebankWordDetokenizer().detokenize(b) if b is not None else None,\n",
    "                                  labeldict[label]) \\\n",
    "                     for i,(a,b,label) in \\\n",
    "                     enumerate(zip(data['text_a'], data['text_b'], data['label']))]\n",
    "    \n",
    "\n",
    "    fooler.model.set_test_dataset(None, examples=test_examples)\n",
    "    \n",
    "    orig_failures = 0.\n",
    "    adv_failures = 0.\n",
    "    changed_rates = []\n",
    "    nums_queries = []\n",
    "    \n",
    "    adv_examples=[]\n",
    "    \n",
    "    for idx, text_a in enumerate(data['text_a']):\n",
    "        if idx % 10 == 0:\n",
    "            print('elapsed time: {}s - {} samples out of {} have been finished!'.format(\n",
    "                round(elapsed_time(),2), idx, data_size))\n",
    "\n",
    "            message = 'accuracy: {:.3f}%, adv accuracy: {:.3f}%, ' \\\n",
    "              'avg changed rate: {:.3f}%, num of queries: {:.1f}\\n'.format((1-orig_failures/(idx+1))*100,\n",
    "                                                                 (1-adv_failures/(idx+1))*100,\n",
    "                                                                 np.mean(changed_rates)*100,\n",
    "                                                                 np.mean(nums_queries))\n",
    "            print(message)\n",
    "\n",
    "        text_b, true_label = data['text_b'][idx], data['label'][idx]\n",
    "                    \n",
    "        new_text, num_changed, orig_label, \\\n",
    "            new_label, num_queries  = fooler.generate_adversarial(task, text_a, text_b, true_label,\n",
    "                                                                  batch_size=batch_size,)\n",
    "        if true_label != orig_label:\n",
    "            orig_failures += 1\n",
    "        else:\n",
    "            nums_queries.append(num_queries)\n",
    "        if true_label != new_label:\n",
    "            adv_failures += 1\n",
    "            if new_text != '':\n",
    "                adv_examples.append(\n",
    "                    InputExample(guid=idx,\n",
    "                                 text_a=TreebankWordDetokenizer().detokenize(text_a) if task == 'mnli' else new_text,\n",
    "                                 text_b=new_text if task == 'mnli' else text_b,\n",
    "                                 label=labeldict[true_label] if task == 'mnli' else true_label))\n",
    "            \n",
    "        changed_rate = 1.0 * num_changed / (len(text_b) if task == 'mnli' else len(text_a))\n",
    "        if true_label == orig_label and true_label != new_label:\n",
    "            changed_rates.append(changed_rate)\n",
    "\n",
    "            \n",
    "    print('elapsed time: {}s - {} samples out of {} have been finished!'.format(\n",
    "        round(elapsed_time(),2), idx+1, data_size))            \n",
    "            \n",
    "    message = 'For target model {}: original accuracy: {:.3f}%, adv accuracy: {:.3f}%, ' \\\n",
    "              'avg changed rate: {:.3f}%, num of queries: {:.1f}\\n'.format(task,\n",
    "                                                                 (1-orig_failures/(idx+1))*100,\n",
    "                                                                 (1-adv_failures/(idx+1))*100,\n",
    "                                                                 np.mean(changed_rates)*100,\n",
    "                                                                 np.mean(nums_queries))\n",
    "    print(message)\n",
    "\n",
    "    return adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routines to create and save the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_eval_model = False\n",
    "\n",
    "eval_model_type = 'FUSE' # can be FUSE or FIVE\n",
    "\n",
    "\n",
    "#FIVE best MNLI params as of 4/14/2020\n",
    "# eval_model_hparams =  {'batch_size': 8, 'use_USE': False, 'stop_words': True, 'perturb_words': 1, \n",
    "#                          'verbose': False, 'vote_avg_logits': True, 'std': 8.139999999999995, 'vector_count': 8}\n",
    "\n",
    "eval_model_hparams =  {'use_USE':True, 'USE_method':\"filter\", 'USE_multiplier':17, 'stop_words':True, 'perturb_words':3,\n",
    "            'candidates_per_word':13, 'total_alternatives':12, 'match_pos':True, 'batch_size':1,'verbose':False, \n",
    "            'vote_avg_logits':True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples(bert_model, task, dataset_path, data_size, batch_size, max_seq_length,\n",
    "                    counter_fitting_embeddings_path, counter_fitting_cos_sim_path, USE_cache_path):\n",
    "    \n",
    "    \n",
    "    print(\"Building TextFooler...\")\n",
    "    fooler = PaperFooler(bert_model.tokenizer,\n",
    "                         bert_model,\n",
    "                         USE_cache_path,\n",
    "                         counter_fitting_embeddings_path,\n",
    "                         counter_fitting_cos_sim_path,\n",
    "                         max_seq_length = max_seq_length)\n",
    "    print(\"TextFooler built!\")\n",
    "\n",
    "    \n",
    "    return generate_samples(task, fooler, dataset_path, data_size, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_examples(bert_model, adv_examples, output_path):\n",
    "    \n",
    "    features = bert_model.get_processor()._create_features(adv_examples)\n",
    "    \n",
    "    torch.save(features, output_path)\n",
    "    \n",
    "    with open(output_path + '.txt', 'w') as output:\n",
    "        for row in adv_examples:\n",
    "            output.write(row.label + '\\t' +\n",
    "                         row.text_a + '\\t' + \n",
    "                         row.text_b + '\\n') if task == 'mnli' else \\\n",
    "            output.write(str(row.label) + ' ' + \n",
    "                         row.text_a + '\\n')\n",
    "            \n",
    "    import pickle\n",
    "    with open(output_path + '.pkl', \"wb\") as f:\n",
    "        pickle.dump(adv_examples, f)\n",
    "    \n",
    "    print('\\nPyTorch-ready InputFeature file saved in {}'.format(output_path))\n",
    "    print('Pickled InputExample file saved in {}.pkl'.format(output_path))\n",
    "    print('Raw text saved in {}.txt'.format(output_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MnliProcessor() if task == 'mnli' else ImdbProcessor()\n",
    "\n",
    "if use_eval_model:\n",
    "    bert_model = (FireBERT_FSE(load_from=model_path, \n",
    "                               processor=processor, \n",
    "                               hparams=eval_model_hparams) if eval_model_type == 'FUSE' else\n",
    "                  FireBERT_FVE(load_from=model_path, \n",
    "                               processor=processor, \n",
    "                               hparams=eval_model_hparams))\n",
    "else:    \n",
    "    bert_model = LightningBertForSequenceClassification(\n",
    "        load_from=model_path, \n",
    "        processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TextFooler...\n",
      "Building vocab...\n",
      "Building cos sim matrix...\n",
      "Load pre-computed cosine similarity matrix from resources/cos_sim_counter_fitting.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using scratch/tf_cache to cache modules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cos sim import finished!\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextFooler built!\n",
      "Data import finished!\n",
      "elapsed time: 14.77s - 0 samples out of 1000 have been finished!\n",
      "accuracy: 100.000%, adv accuracy: 100.000%, avg changed rate: nan%, num of queries: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/kevin/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 115.93s - 10 samples out of 1000 have been finished!\n",
      "accuracy: 90.909%, adv accuracy: 18.182%, avg changed rate: 13.232%, num of queries: 1305.8\n",
      "\n",
      "elapsed time: 90.54s - 20 samples out of 1000 have been finished!\n",
      "accuracy: 95.238%, adv accuracy: 9.524%, avg changed rate: 9.344%, num of queries: 1067.3\n",
      "\n",
      "elapsed time: 157.43s - 30 samples out of 1000 have been finished!\n",
      "accuracy: 96.774%, adv accuracy: 6.452%, avg changed rate: 8.907%, num of queries: 1153.0\n",
      "\n",
      "elapsed time: 79.96s - 40 samples out of 1000 have been finished!\n",
      "accuracy: 97.561%, adv accuracy: 4.878%, avg changed rate: 8.754%, num of queries: 1060.2\n",
      "\n",
      "elapsed time: 123.51s - 50 samples out of 1000 have been finished!\n",
      "accuracy: 96.078%, adv accuracy: 5.882%, avg changed rate: 8.147%, num of queries: 1075.1\n",
      "\n",
      "elapsed time: 84.3s - 60 samples out of 1000 have been finished!\n",
      "accuracy: 93.443%, adv accuracy: 4.918%, avg changed rate: 7.693%, num of queries: 1046.3\n",
      "\n",
      "elapsed time: 82.34s - 70 samples out of 1000 have been finished!\n",
      "accuracy: 92.958%, adv accuracy: 4.225%, avg changed rate: 8.615%, num of queries: 1035.0\n",
      "\n",
      "elapsed time: 110.84s - 80 samples out of 1000 have been finished!\n",
      "accuracy: 93.827%, adv accuracy: 3.704%, avg changed rate: 9.222%, num of queries: 1047.2\n",
      "\n",
      "elapsed time: 69.18s - 90 samples out of 1000 have been finished!\n",
      "accuracy: 92.308%, adv accuracy: 3.297%, avg changed rate: 9.443%, num of queries: 1034.6\n",
      "\n",
      "elapsed time: 158.53s - 100 samples out of 1000 have been finished!\n",
      "accuracy: 93.069%, adv accuracy: 2.970%, avg changed rate: 9.807%, num of queries: 1087.4\n",
      "\n",
      "elapsed time: 81.22s - 110 samples out of 1000 have been finished!\n",
      "accuracy: 93.694%, adv accuracy: 2.703%, avg changed rate: 9.666%, num of queries: 1060.0\n",
      "\n",
      "elapsed time: 69.75s - 120 samples out of 1000 have been finished!\n",
      "accuracy: 93.388%, adv accuracy: 2.479%, avg changed rate: 9.302%, num of queries: 1034.3\n",
      "\n",
      "elapsed time: 100.43s - 130 samples out of 1000 have been finished!\n",
      "accuracy: 93.893%, adv accuracy: 2.290%, avg changed rate: 9.716%, num of queries: 1036.1\n",
      "\n",
      "elapsed time: 290.95s - 140 samples out of 1000 have been finished!\n",
      "accuracy: 93.617%, adv accuracy: 2.128%, avg changed rate: 9.837%, num of queries: 1121.1\n",
      "\n",
      "elapsed time: 87.01s - 150 samples out of 1000 have been finished!\n",
      "accuracy: 93.377%, adv accuracy: 1.987%, avg changed rate: 9.549%, num of queries: 1102.6\n",
      "\n",
      "elapsed time: 91.54s - 160 samples out of 1000 have been finished!\n",
      "accuracy: 93.168%, adv accuracy: 1.863%, avg changed rate: 9.737%, num of queries: 1099.2\n",
      "\n",
      "elapsed time: 100.99s - 170 samples out of 1000 have been finished!\n",
      "accuracy: 93.567%, adv accuracy: 1.754%, avg changed rate: 9.679%, num of queries: 1092.3\n",
      "\n",
      "elapsed time: 143.26s - 180 samples out of 1000 have been finished!\n",
      "accuracy: 93.923%, adv accuracy: 1.657%, avg changed rate: 9.400%, num of queries: 1100.6\n",
      "\n",
      "elapsed time: 87.57s - 190 samples out of 1000 have been finished!\n",
      "accuracy: 94.241%, adv accuracy: 1.571%, avg changed rate: 9.285%, num of queries: 1088.2\n",
      "\n",
      "elapsed time: 88.32s - 200 samples out of 1000 have been finished!\n",
      "accuracy: 94.030%, adv accuracy: 1.493%, avg changed rate: 9.402%, num of queries: 1082.2\n",
      "\n",
      "elapsed time: 114.59s - 210 samples out of 1000 have been finished!\n",
      "accuracy: 93.839%, adv accuracy: 1.422%, avg changed rate: 9.646%, num of queries: 1093.0\n",
      "\n",
      "elapsed time: 71.27s - 220 samples out of 1000 have been finished!\n",
      "accuracy: 93.665%, adv accuracy: 1.357%, avg changed rate: 9.751%, num of queries: 1082.1\n",
      "\n",
      "elapsed time: 106.05s - 230 samples out of 1000 have been finished!\n",
      "accuracy: 93.939%, adv accuracy: 1.732%, avg changed rate: 9.659%, num of queries: 1080.9\n",
      "\n",
      "elapsed time: 98.67s - 240 samples out of 1000 have been finished!\n",
      "accuracy: 94.191%, adv accuracy: 1.660%, avg changed rate: 9.602%, num of queries: 1076.7\n",
      "\n",
      "elapsed time: 94.37s - 250 samples out of 1000 have been finished!\n",
      "accuracy: 94.422%, adv accuracy: 1.594%, avg changed rate: 9.591%, num of queries: 1070.6\n",
      "\n",
      "elapsed time: 134.75s - 260 samples out of 1000 have been finished!\n",
      "accuracy: 93.487%, adv accuracy: 1.916%, avg changed rate: 9.635%, num of queries: 1089.5\n",
      "\n",
      "elapsed time: 85.33s - 270 samples out of 1000 have been finished!\n",
      "accuracy: 93.358%, adv accuracy: 1.845%, avg changed rate: 9.546%, num of queries: 1082.5\n",
      "\n",
      "elapsed time: 179.56s - 280 samples out of 1000 have been finished!\n",
      "accuracy: 93.594%, adv accuracy: 1.779%, avg changed rate: 9.609%, num of queries: 1100.0\n",
      "\n",
      "elapsed time: 130.54s - 290 samples out of 1000 have been finished!\n",
      "accuracy: 93.471%, adv accuracy: 1.718%, avg changed rate: 9.562%, num of queries: 1103.4\n",
      "\n",
      "elapsed time: 103.66s - 300 samples out of 1000 have been finished!\n",
      "accuracy: 93.688%, adv accuracy: 2.326%, avg changed rate: 9.682%, num of queries: 1105.1\n",
      "\n",
      "elapsed time: 62.56s - 310 samples out of 1000 have been finished!\n",
      "accuracy: 93.248%, adv accuracy: 2.251%, avg changed rate: 9.578%, num of queries: 1095.5\n",
      "\n",
      "elapsed time: 129.47s - 320 samples out of 1000 have been finished!\n",
      "accuracy: 93.146%, adv accuracy: 2.492%, avg changed rate: 9.589%, num of queries: 1102.7\n",
      "\n",
      "elapsed time: 74.89s - 330 samples out of 1000 have been finished!\n",
      "accuracy: 93.353%, adv accuracy: 2.719%, avg changed rate: 9.583%, num of queries: 1092.4\n",
      "\n",
      "elapsed time: 80.65s - 340 samples out of 1000 have been finished!\n",
      "accuracy: 93.548%, adv accuracy: 2.639%, avg changed rate: 9.556%, num of queries: 1084.3\n",
      "\n",
      "elapsed time: 93.73s - 350 samples out of 1000 have been finished!\n",
      "accuracy: 93.732%, adv accuracy: 2.564%, avg changed rate: 9.532%, num of queries: 1079.6\n",
      "\n",
      "elapsed time: 96.85s - 360 samples out of 1000 have been finished!\n",
      "accuracy: 93.906%, adv accuracy: 2.770%, avg changed rate: 9.533%, num of queries: 1077.2\n",
      "\n",
      "elapsed time: 147.18s - 370 samples out of 1000 have been finished!\n",
      "accuracy: 94.070%, adv accuracy: 2.695%, avg changed rate: 9.603%, num of queries: 1086.1\n",
      "\n",
      "elapsed time: 65.57s - 380 samples out of 1000 have been finished!\n",
      "accuracy: 93.701%, adv accuracy: 2.625%, avg changed rate: 9.540%, num of queries: 1078.5\n",
      "\n",
      "elapsed time: 94.55s - 390 samples out of 1000 have been finished!\n",
      "accuracy: 93.862%, adv accuracy: 2.558%, avg changed rate: 9.570%, num of queries: 1075.5\n",
      "\n",
      "elapsed time: 341.08s - 400 samples out of 1000 have been finished!\n",
      "accuracy: 94.015%, adv accuracy: 2.494%, avg changed rate: 9.580%, num of queries: 1110.9\n",
      "\n",
      "elapsed time: 102.69s - 410 samples out of 1000 have been finished!\n",
      "accuracy: 94.161%, adv accuracy: 2.433%, avg changed rate: 9.564%, num of queries: 1107.6\n",
      "\n",
      "elapsed time: 83.49s - 420 samples out of 1000 have been finished!\n",
      "accuracy: 94.299%, adv accuracy: 2.375%, avg changed rate: 9.598%, num of queries: 1099.3\n",
      "\n",
      "elapsed time: 95.05s - 430 samples out of 1000 have been finished!\n",
      "accuracy: 94.432%, adv accuracy: 2.320%, avg changed rate: 9.554%, num of queries: 1094.9\n",
      "\n",
      "elapsed time: 115.25s - 440 samples out of 1000 have been finished!\n",
      "accuracy: 94.558%, adv accuracy: 2.268%, avg changed rate: 9.576%, num of queries: 1094.6\n",
      "\n",
      "elapsed time: 155.46s - 450 samples out of 1000 have been finished!\n",
      "accuracy: 94.678%, adv accuracy: 2.217%, avg changed rate: 9.531%, num of queries: 1100.1\n",
      "\n",
      "elapsed time: 129.6s - 460 samples out of 1000 have been finished!\n",
      "accuracy: 94.577%, adv accuracy: 2.169%, avg changed rate: 9.468%, num of queries: 1102.5\n",
      "\n",
      "elapsed time: 128.37s - 470 samples out of 1000 have been finished!\n",
      "accuracy: 94.692%, adv accuracy: 2.335%, avg changed rate: 9.433%, num of queries: 1102.4\n",
      "\n",
      "elapsed time: 158.72s - 480 samples out of 1000 have been finished!\n",
      "accuracy: 94.802%, adv accuracy: 2.287%, avg changed rate: 9.518%, num of queries: 1111.5\n",
      "\n",
      "elapsed time: 134.32s - 490 samples out of 1000 have been finished!\n",
      "accuracy: 94.705%, adv accuracy: 2.240%, avg changed rate: 9.549%, num of queries: 1115.8\n",
      "\n",
      "elapsed time: 92.7s - 500 samples out of 1000 have been finished!\n",
      "accuracy: 94.611%, adv accuracy: 2.196%, avg changed rate: 9.531%, num of queries: 1112.8\n",
      "\n",
      "elapsed time: 128.13s - 510 samples out of 1000 have been finished!\n",
      "accuracy: 94.521%, adv accuracy: 2.348%, avg changed rate: 9.458%, num of queries: 1114.7\n",
      "\n",
      "elapsed time: 173.88s - 520 samples out of 1000 have been finished!\n",
      "accuracy: 94.626%, adv accuracy: 2.879%, avg changed rate: 9.536%, num of queries: 1127.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 85.52s - 530 samples out of 1000 have been finished!\n",
      "accuracy: 94.727%, adv accuracy: 2.825%, avg changed rate: 9.597%, num of queries: 1121.9\n",
      "\n",
      "elapsed time: 126.56s - 540 samples out of 1000 have been finished!\n",
      "accuracy: 94.824%, adv accuracy: 2.773%, avg changed rate: 9.566%, num of queries: 1121.1\n",
      "\n",
      "elapsed time: 64.37s - 550 samples out of 1000 have been finished!\n",
      "accuracy: 94.737%, adv accuracy: 2.722%, avg changed rate: 9.570%, num of queries: 1115.0\n",
      "\n",
      "elapsed time: 163.43s - 560 samples out of 1000 have been finished!\n",
      "accuracy: 94.831%, adv accuracy: 2.852%, avg changed rate: 9.583%, num of queries: 1120.7\n",
      "\n",
      "elapsed time: 71.1s - 570 samples out of 1000 have been finished!\n",
      "accuracy: 94.746%, adv accuracy: 2.802%, avg changed rate: 9.619%, num of queries: 1115.8\n",
      "\n",
      "elapsed time: 81.1s - 580 samples out of 1000 have been finished!\n",
      "accuracy: 94.836%, adv accuracy: 2.754%, avg changed rate: 9.631%, num of queries: 1110.8\n",
      "\n",
      "elapsed time: 69.23s - 590 samples out of 1000 have been finished!\n",
      "accuracy: 94.755%, adv accuracy: 2.707%, avg changed rate: 9.557%, num of queries: 1103.3\n",
      "\n",
      "elapsed time: 48.71s - 600 samples out of 1000 have been finished!\n",
      "accuracy: 94.343%, adv accuracy: 2.662%, avg changed rate: 9.515%, num of queries: 1098.4\n",
      "\n",
      "elapsed time: 79.76s - 610 samples out of 1000 have been finished!\n",
      "accuracy: 94.435%, adv accuracy: 2.619%, avg changed rate: 9.531%, num of queries: 1093.9\n",
      "\n",
      "elapsed time: 85.06s - 620 samples out of 1000 have been finished!\n",
      "accuracy: 94.525%, adv accuracy: 2.576%, avg changed rate: 9.482%, num of queries: 1089.2\n",
      "\n",
      "elapsed time: 106.94s - 630 samples out of 1000 have been finished!\n",
      "accuracy: 94.612%, adv accuracy: 2.694%, avg changed rate: 9.491%, num of queries: 1089.7\n",
      "\n",
      "elapsed time: 66.14s - 640 samples out of 1000 have been finished!\n",
      "accuracy: 94.696%, adv accuracy: 2.808%, avg changed rate: 9.433%, num of queries: 1082.2\n",
      "\n",
      "elapsed time: 88.6s - 650 samples out of 1000 have been finished!\n",
      "accuracy: 94.777%, adv accuracy: 2.765%, avg changed rate: 9.458%, num of queries: 1079.5\n",
      "\n",
      "elapsed time: 94.21s - 660 samples out of 1000 have been finished!\n",
      "accuracy: 94.856%, adv accuracy: 2.874%, avg changed rate: 9.508%, num of queries: 1078.2\n",
      "\n",
      "elapsed time: 93.67s - 670 samples out of 1000 have been finished!\n",
      "accuracy: 94.784%, adv accuracy: 2.981%, avg changed rate: 9.531%, num of queries: 1077.7\n",
      "\n",
      "elapsed time: 146.4s - 680 samples out of 1000 have been finished!\n",
      "accuracy: 94.860%, adv accuracy: 2.937%, avg changed rate: 9.534%, num of queries: 1080.9\n",
      "\n",
      "elapsed time: 78.55s - 690 samples out of 1000 have been finished!\n",
      "accuracy: 94.790%, adv accuracy: 2.894%, avg changed rate: 9.517%, num of queries: 1077.3\n",
      "\n",
      "elapsed time: 64.66s - 700 samples out of 1000 have been finished!\n",
      "accuracy: 94.722%, adv accuracy: 2.853%, avg changed rate: 9.488%, num of queries: 1072.1\n",
      "\n",
      "elapsed time: 117.68s - 710 samples out of 1000 have been finished!\n",
      "accuracy: 94.655%, adv accuracy: 2.813%, avg changed rate: 9.575%, num of queries: 1074.9\n",
      "\n",
      "elapsed time: 81.29s - 720 samples out of 1000 have been finished!\n",
      "accuracy: 94.730%, adv accuracy: 2.774%, avg changed rate: 9.570%, num of queries: 1069.7\n",
      "\n",
      "elapsed time: 117.7s - 730 samples out of 1000 have been finished!\n",
      "accuracy: 94.802%, adv accuracy: 3.146%, avg changed rate: 9.535%, num of queries: 1070.5\n",
      "\n",
      "elapsed time: 118.02s - 740 samples out of 1000 have been finished!\n",
      "accuracy: 94.737%, adv accuracy: 3.104%, avg changed rate: 9.600%, num of queries: 1072.7\n",
      "\n",
      "elapsed time: 69.85s - 750 samples out of 1000 have been finished!\n",
      "accuracy: 94.674%, adv accuracy: 3.063%, avg changed rate: 9.596%, num of queries: 1068.5\n",
      "\n",
      "elapsed time: 98.89s - 760 samples out of 1000 have been finished!\n",
      "accuracy: 94.744%, adv accuracy: 3.154%, avg changed rate: 9.600%, num of queries: 1067.3\n",
      "\n",
      "elapsed time: 75.37s - 770 samples out of 1000 have been finished!\n",
      "accuracy: 94.682%, adv accuracy: 3.113%, avg changed rate: 9.590%, num of queries: 1063.8\n",
      "\n",
      "elapsed time: 121.91s - 780 samples out of 1000 have been finished!\n",
      "accuracy: 94.750%, adv accuracy: 3.329%, avg changed rate: 9.536%, num of queries: 1061.7\n",
      "\n",
      "elapsed time: 152.34s - 790 samples out of 1000 have been finished!\n",
      "accuracy: 94.817%, adv accuracy: 3.413%, avg changed rate: 9.478%, num of queries: 1063.6\n",
      "\n",
      "elapsed time: 127.15s - 800 samples out of 1000 have been finished!\n",
      "accuracy: 94.757%, adv accuracy: 3.496%, avg changed rate: 9.514%, num of queries: 1067.1\n",
      "\n",
      "elapsed time: 203.22s - 810 samples out of 1000 have been finished!\n",
      "accuracy: 94.821%, adv accuracy: 3.453%, avg changed rate: 9.554%, num of queries: 1074.3\n",
      "\n",
      "elapsed time: 103.19s - 820 samples out of 1000 have been finished!\n",
      "accuracy: 94.884%, adv accuracy: 3.410%, avg changed rate: 9.550%, num of queries: 1071.4\n",
      "\n",
      "elapsed time: 135.92s - 830 samples out of 1000 have been finished!\n",
      "accuracy: 94.946%, adv accuracy: 3.490%, avg changed rate: 9.620%, num of queries: 1074.9\n",
      "\n",
      "elapsed time: 130.91s - 840 samples out of 1000 have been finished!\n",
      "accuracy: 94.887%, adv accuracy: 3.567%, avg changed rate: 9.648%, num of queries: 1078.4\n",
      "\n",
      "elapsed time: 86.52s - 850 samples out of 1000 have been finished!\n",
      "accuracy: 94.830%, adv accuracy: 3.525%, avg changed rate: 9.627%, num of queries: 1076.1\n",
      "\n",
      "elapsed time: 114.78s - 860 samples out of 1000 have been finished!\n",
      "accuracy: 94.890%, adv accuracy: 3.484%, avg changed rate: 9.681%, num of queries: 1076.3\n",
      "\n",
      "elapsed time: 96.94s - 870 samples out of 1000 have been finished!\n",
      "accuracy: 94.834%, adv accuracy: 3.444%, avg changed rate: 9.708%, num of queries: 1075.6\n",
      "\n",
      "elapsed time: 121.7s - 880 samples out of 1000 have been finished!\n",
      "accuracy: 94.892%, adv accuracy: 3.405%, avg changed rate: 9.681%, num of queries: 1074.5\n",
      "\n",
      "elapsed time: 170.63s - 890 samples out of 1000 have been finished!\n",
      "accuracy: 94.949%, adv accuracy: 3.367%, avg changed rate: 9.798%, num of queries: 1080.9\n",
      "\n",
      "elapsed time: 84.68s - 900 samples out of 1000 have been finished!\n",
      "accuracy: 94.895%, adv accuracy: 3.330%, avg changed rate: 9.786%, num of queries: 1078.7\n",
      "\n",
      "elapsed time: 142.68s - 910 samples out of 1000 have been finished!\n",
      "accuracy: 94.951%, adv accuracy: 3.403%, avg changed rate: 9.786%, num of queries: 1079.9\n",
      "\n",
      "elapsed time: 364.09s - 920 samples out of 1000 have been finished!\n",
      "accuracy: 95.005%, adv accuracy: 3.366%, avg changed rate: 9.874%, num of queries: 1098.1\n",
      "\n",
      "elapsed time: 247.88s - 930 samples out of 1000 have been finished!\n",
      "accuracy: 95.059%, adv accuracy: 3.330%, avg changed rate: 9.940%, num of queries: 1106.9\n",
      "\n",
      "elapsed time: 127.02s - 940 samples out of 1000 have been finished!\n",
      "accuracy: 95.112%, adv accuracy: 3.401%, avg changed rate: 9.897%, num of queries: 1106.4\n",
      "\n",
      "elapsed time: 81.46s - 950 samples out of 1000 have been finished!\n",
      "accuracy: 95.058%, adv accuracy: 3.365%, avg changed rate: 9.909%, num of queries: 1104.4\n",
      "\n",
      "elapsed time: 146.65s - 960 samples out of 1000 have been finished!\n",
      "accuracy: 95.109%, adv accuracy: 3.434%, avg changed rate: 9.884%, num of queries: 1104.5\n",
      "\n",
      "elapsed time: 166.08s - 970 samples out of 1000 have been finished!\n",
      "accuracy: 95.160%, adv accuracy: 3.399%, avg changed rate: 9.889%, num of queries: 1106.5\n",
      "\n",
      "elapsed time: 74.97s - 980 samples out of 1000 have been finished!\n",
      "accuracy: 95.107%, adv accuracy: 3.364%, avg changed rate: 9.902%, num of queries: 1104.0\n",
      "\n",
      "elapsed time: 71.34s - 990 samples out of 1000 have been finished!\n",
      "accuracy: 95.156%, adv accuracy: 3.330%, avg changed rate: 9.870%, num of queries: 1098.4\n",
      "\n",
      "elapsed time: 120.19s - 1000 samples out of 1000 have been finished!\n",
      "For target model imdb: original accuracy: 95.100%, adv accuracy: 3.200%, avg changed rate: 9.872%, num of queries: 1097.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adv_examples = create_examples(bert_model, task, dataset_path, data_size, batch_size, 128 if task =='mnli' else 256, \n",
    "                               counter_fitting_embeddings_path, counter_fitting_cos_sim_path, USE_cache_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment if you want to see the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment or uncomment depending on whether you want to save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_examples(bert_model, adv_examples, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
